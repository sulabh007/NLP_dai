{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment 6</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name : Viraj Patil\n",
    "\n",
    "PRN  : 230940128038 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 07:45:10.962168: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-20 07:45:11.621511: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-20 07:45:13.205833: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-20 07:45:13.206083: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-20 07:45:13.398143: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-20 07:45:13.957707: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-20 07:45:13.959717: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-20 07:45:24.453071: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "from os import listdir\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding, Conv1D, MaxPooling1D\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    tokens1 = word_tokenize(text)\n",
    "    tokens2 = [x.lower() for x in tokens1 if x.isalpha() or x.isdigit()]\n",
    "    tokens3 = [x for x in tokens2 if x not in stopwords.words('english')]\n",
    "    tokens4 = []\n",
    "    tags = pos_tag(tokens3)\n",
    "    for word in tags:\n",
    "        if word[1].startswith('N'):\n",
    "            tokens4.append(wnl.lemmatize(word[0], pos='n'))\n",
    "        if word[1].startswith('V'):\n",
    "            tokens4.append(wnl.lemmatize(word[0], pos='v'))\n",
    "        if word[1].startswith('R'):\n",
    "            tokens4.append(wnl.lemmatize(word[0], pos='r'))\n",
    "        if word[1].startswith('J'):\n",
    "            tokens4.append(wnl.lemmatize(word[0], pos='a'))\n",
    "    \n",
    "    return tokens4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer=clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Phusical GPUs 0 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "try:\n",
    "    for g in gpus:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print (len(gpus), 'Phusical GPUs', len(logical_gpus), 'Logical GPUs')\n",
    "except:\n",
    "    print ('invalid device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Household</td>\n",
       "      <td>Paper Plane Design Framed Wall Hanging Motivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'Floral' Framed Painting (Wood, 30 inch x ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'UV Textured Modern Art Print Framed' Pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF Flower Print Framed Painting (Synthetic, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Household</td>\n",
       "      <td>Incredible Gifts India Wooden Happy Birthday U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50420</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Strontium MicroSD Class 10 8GB Memory Card (Bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50421</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>CrossBeats Wave Waterproof Bluetooth Wireless ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50422</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Karbonn Titanium Wind W4 (White) Karbonn Titan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50423</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Samsung Guru FM Plus (SM-B110E/D, Black) Colou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50424</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Micromax Canvas Win W121 (White)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50425 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             class                                               text\n",
       "0        Household  Paper Plane Design Framed Wall Hanging Motivat...\n",
       "1        Household  SAF 'Floral' Framed Painting (Wood, 30 inch x ...\n",
       "2        Household  SAF 'UV Textured Modern Art Print Framed' Pain...\n",
       "3        Household  SAF Flower Print Framed Painting (Synthetic, 1...\n",
       "4        Household  Incredible Gifts India Wooden Happy Birthday U...\n",
       "...            ...                                                ...\n",
       "50420  Electronics  Strontium MicroSD Class 10 8GB Memory Card (Bl...\n",
       "50421  Electronics  CrossBeats Wave Waterproof Bluetooth Wireless ...\n",
       "50422  Electronics  Karbonn Titanium Wind W4 (White) Karbonn Titan...\n",
       "50423  Electronics  Samsung Guru FM Plus (SM-B110E/D, Black) Colou...\n",
       "50424  Electronics                   Micromax Canvas Win W121 (White)\n",
       "\n",
       "[50425 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ecommerceDatasetNLP.csv', header=None, names=['class','text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Household                 19313\n",
       "Books                     11820\n",
       "Electronics               10621\n",
       "Clothing & Accessories     8671\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/anaconda3/envs/NLP/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/dai/anaconda3/envs/NLP/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/dai/anaconda3/envs/NLP/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='count', ylabel='class'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y=df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class    0\n",
       "text     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [paper, plane, design, frame, wall, hang, moti...\n",
       "1        [saf, frame, paint, wood, inch, x, inch, speci...\n",
       "2        [saf, textured, modern, art, print, frame, pai...\n",
       "3        [saf, flower, print, frame, paint, synthetic, ...\n",
       "4        [incredible, gift, india, wooden, happy, birth...\n",
       "                               ...                        \n",
       "50420    [strontium, microsd, class, memory, card, blac...\n",
       "50421    [crossbeats, wave, waterproof, bluetooth, wire...\n",
       "50422    [karbonn, titanium, white, karbonn, titanium, ...\n",
       "50423    [samsung, guru, fm, black, colour, black, comp...\n",
       "50424                       [micromax, canvas, win, white]\n",
       "Name: text, Length: 50424, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Household</td>\n",
       "      <td>Paper Plane Design Framed Wall Hanging Motivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'Floral' Framed Painting (Wood, 30 inch x ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF 'UV Textured Modern Art Print Framed' Pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Household</td>\n",
       "      <td>SAF Flower Print Framed Painting (Synthetic, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Household</td>\n",
       "      <td>Incredible Gifts India Wooden Happy Birthday U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50420</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Strontium MicroSD Class 10 8GB Memory Card (Bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50421</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>CrossBeats Wave Waterproof Bluetooth Wireless ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50422</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Karbonn Titanium Wind W4 (White) Karbonn Titan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50423</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Samsung Guru FM Plus (SM-B110E/D, Black) Colou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50424</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Micromax Canvas Win W121 (White)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50424 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             class                                               text\n",
       "0        Household  Paper Plane Design Framed Wall Hanging Motivat...\n",
       "1        Household  SAF 'Floral' Framed Painting (Wood, 30 inch x ...\n",
       "2        Household  SAF 'UV Textured Modern Art Print Framed' Pain...\n",
       "3        Household  SAF Flower Print Framed Painting (Synthetic, 1...\n",
       "4        Household  Incredible Gifts India Wooden Happy Birthday U...\n",
       "...            ...                                                ...\n",
       "50420  Electronics  Strontium MicroSD Class 10 8GB Memory Card (Bl...\n",
       "50421  Electronics  CrossBeats Wave Waterproof Bluetooth Wireless ...\n",
       "50422  Electronics  Karbonn Titanium Wind W4 (White) Karbonn Titan...\n",
       "50423  Electronics  Samsung Guru FM Plus (SM-B110E/D, Black) Colou...\n",
       "50424  Electronics                   Micromax Canvas Win W121 (White)\n",
       "\n",
       "[50424 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Paper Plane Design Framed Wall Hanging Motivat...\n",
       "1        SAF 'Floral' Framed Painting (Wood, 30 inch x ...\n",
       "2        SAF 'UV Textured Modern Art Print Framed' Pain...\n",
       "3        SAF Flower Print Framed Painting (Synthetic, 1...\n",
       "4        Incredible Gifts India Wooden Happy Birthday U...\n",
       "                               ...                        \n",
       "50420    Strontium MicroSD Class 10 8GB Memory Card (Bl...\n",
       "50421    CrossBeats Wave Waterproof Bluetooth Wireless ...\n",
       "50422    Karbonn Titanium Wind W4 (White) Karbonn Titan...\n",
       "50423    Samsung Guru FM Plus (SM-B110E/D, Black) Colou...\n",
       "50424                     Micromax Canvas Win W121 (White)\n",
       "Name: text, Length: 50424, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df['text']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_vect = tfidf.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dai/anaconda3/envs/NLP/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/dai/anaconda3/envs/NLP/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state= 0, stratify= y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37818,), (12606,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # prepare regex for char filtering\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    # remove puctuation from each word\n",
    "    tokens = [re_punc.sub('', w) for w in tokens]\n",
    "    # remove reamaning tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3814568146.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[21], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    model.add(Dense(100,input_shape = (vocab_size,) activation = 'relu'))\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "def define_model(vocab_size):\n",
    "  # define network\n",
    "  model = Sequential()\n",
    "  # model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "  model.add(Dense(vocab_size, activation = 'relu'))\n",
    "  model.add(Dense(100,input_shape = (vocab_size,), activation = 'relu'))\n",
    "  model.add(Dense(10, activation = 'relu'))\n",
    "  model.add(Dense(1,  activation = 'softmax'))\n",
    "  # compile network\n",
    "  model.compile(loss = 'CategoricalCrossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "  # summerize defined model\n",
    "  model.summary()\n",
    "  plot_model(model, to_file='model.png',show_shapes=True)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "  tokenizer = Tokenizer()\n",
    "  tokenizer.fit_on_texts(lines)\n",
    "  return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tokenizer\n",
    "tokenizer = create_tokenizer(x_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(689, 84727)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enocde data\n",
    "x_train = tokenizer.texts_to_matrix(x_train, mode = 'binary')\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12606, 84727)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = tokenizer.texts_to_matrix(x_test, mode = 'binary')\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'dry': 1439,\n",
       "             'vegetables': 374,\n",
       "             'slices': 62,\n",
       "             'etc': 1945,\n",
       "             'peels': 5,\n",
       "             'used': 3877,\n",
       "             'fruit': 319,\n",
       "             'slicer': 91,\n",
       "             'can': 9702,\n",
       "             'as': 9156,\n",
       "             '1': 7925,\n",
       "             '3': 6490,\n",
       "             'peeler': 37,\n",
       "             'grates': 8,\n",
       "             'cheese': 127,\n",
       "             'fruits': 327,\n",
       "             'grater': 50,\n",
       "             'multibranded': 2,\n",
       "             'in': 20325,\n",
       "             'vegetable': 255,\n",
       "             'be': 9231,\n",
       "             'navisha': 3,\n",
       "             'and': 28321,\n",
       "             'awakening': 26,\n",
       "             'child': 427,\n",
       "             'a': 21299,\n",
       "             'abuse': 16,\n",
       "             'to': 22939,\n",
       "             'survivor': 10,\n",
       "             'from': 12278,\n",
       "             'journey': 381,\n",
       "             'healer': 7,\n",
       "             'wounded': 2,\n",
       "             'the': 24714,\n",
       "             'sexual': 23,\n",
       "             'true': 660,\n",
       "             'of': 24330,\n",
       "             'story': 726,\n",
       "             'waist': 648,\n",
       "             'three': 1067,\n",
       "             'low': 1215,\n",
       "             'cotton': 3507,\n",
       "             'prints': 299,\n",
       "             'set': 5290,\n",
       "             'thong': 44,\n",
       "             \"women's\": 1901,\n",
       "             'crazy': 42,\n",
       "             'description': 2325,\n",
       "             'us': 1808,\n",
       "             'you': 12131,\n",
       "             'monitor': 647,\n",
       "             'category': 165,\n",
       "             'elastic': 523,\n",
       "             'when': 3568,\n",
       "             'list': 411,\n",
       "             'will': 6367,\n",
       "             'asap': 28,\n",
       "             'for': 23702,\n",
       "             'understand': 550,\n",
       "             'punk': 4,\n",
       "             'linked': 39,\n",
       "             'might': 480,\n",
       "             'tell': 187,\n",
       "             'halloween': 19,\n",
       "             'kindly': 316,\n",
       "             'packing': 226,\n",
       "             'best': 4296,\n",
       "             '67g': 1,\n",
       "             'deviation': 74,\n",
       "             'give': 1964,\n",
       "             'please': 1393,\n",
       "             'men': 1140,\n",
       "             'hand': 2240,\n",
       "             'service': 857,\n",
       "             'ornaments': 38,\n",
       "             'unisex': 388,\n",
       "             'have': 5424,\n",
       "             'chains': 25,\n",
       "             'leoie': 16,\n",
       "             'any': 5080,\n",
       "             'much': 1423,\n",
       "             'bracelet': 48,\n",
       "             'metal': 1441,\n",
       "             'skeleton': 8,\n",
       "             'we': 3293,\n",
       "             'problem': 408,\n",
       "             'individually': 87,\n",
       "             'so': 3676,\n",
       "             'packed': 464,\n",
       "             'due': 1075,\n",
       "             'settings': 637,\n",
       "             'women': 1672,\n",
       "             'different': 2214,\n",
       "             'weight': 2237,\n",
       "             'scary': 20,\n",
       "             'style': 3926,\n",
       "             'colors': 1367,\n",
       "             'thank': 158,\n",
       "             'solve': 160,\n",
       "             'differ': 103,\n",
       "             'first': 1828,\n",
       "             'easier': 486,\n",
       "             'let': 737,\n",
       "             'anorexia': 2,\n",
       "             'who': 2171,\n",
       "             'help': 2100,\n",
       "             'dirty': 151,\n",
       "             'fried': 37,\n",
       "             'into': 3409,\n",
       "             'especially': 478,\n",
       "             'longer': 654,\n",
       "             '2': 7436,\n",
       "             'shapes': 280,\n",
       "             'ergonomic': 453,\n",
       "             '5pcs': 31,\n",
       "             'their': 2687,\n",
       "             'brush': 488,\n",
       "             'stainless': 1858,\n",
       "             'slomg': 1,\n",
       "             'great': 3140,\n",
       "             'pan': 305,\n",
       "             'like': 3301,\n",
       "             'fun': 892,\n",
       "             'steel': 2670,\n",
       "             'micky': 4,\n",
       "             'little': 1101,\n",
       "             'finger': 210,\n",
       "             'cooking': 678,\n",
       "             'new': 4541,\n",
       "             'suitable': 1498,\n",
       "             '6': 3912,\n",
       "             'made': 6650,\n",
       "             'water': 2328,\n",
       "             'food': 1308,\n",
       "             'gets': 298,\n",
       "             'operations': 213,\n",
       "             'quicker': 60,\n",
       "             'very': 2987,\n",
       "             '7': 2491,\n",
       "             'protect': 822,\n",
       "             'round': 1085,\n",
       "             'lovely': 218,\n",
       "             'by': 7731,\n",
       "             'shaper': 63,\n",
       "             'flower': 290,\n",
       "             'are': 9290,\n",
       "             'tools': 706,\n",
       "             'use': 6090,\n",
       "             'star': 498,\n",
       "             'maker': 370,\n",
       "             'heart': 480,\n",
       "             'durable': 2328,\n",
       "             'come': 1201,\n",
       "             'safe': 1731,\n",
       "             'egg': 191,\n",
       "             'washable': 387,\n",
       "             'griddle': 4,\n",
       "             'no': 3732,\n",
       "             'family': 1453,\n",
       "             'mould': 83,\n",
       "             'without': 2549,\n",
       "             'heat': 1141,\n",
       "             'molds': 24,\n",
       "             'handle': 1376,\n",
       "             'or': 9824,\n",
       "             'adjustable': 983,\n",
       "             'shape': 1007,\n",
       "             'his': 2629,\n",
       "             'angles': 115,\n",
       "             'tool': 842,\n",
       "             '4pcs': 43,\n",
       "             'breakfast': 87,\n",
       "             'connectwide': 1,\n",
       "             \"it's\": 1461,\n",
       "             'easy': 6139,\n",
       "             'non': 1802,\n",
       "             'kitchen': 2083,\n",
       "             'choice': 1139,\n",
       "             'cook': 288,\n",
       "             'makes': 3072,\n",
       "             'damages': 83,\n",
       "             'thicker': 34,\n",
       "             'after': 2313,\n",
       "             'stainl': 1,\n",
       "             'once': 1019,\n",
       "             'bring': 856,\n",
       "             'out': 3582,\n",
       "             'frying': 103,\n",
       "             'biscuit': 18,\n",
       "             'grade': 917,\n",
       "             'worry': 539,\n",
       "             'make': 4085,\n",
       "             'vivid': 208,\n",
       "             'way': 2341,\n",
       "             'stick': 703,\n",
       "             'plum': 13,\n",
       "             'comes': 3930,\n",
       "             'gadgets': 147,\n",
       "             '100': 2967,\n",
       "             '1st': 45,\n",
       "             'good': 2511,\n",
       "             'several': 697,\n",
       "             'pieces': 1146,\n",
       "             'it': 13346,\n",
       "             'your': 14259,\n",
       "             'omelette': 21,\n",
       "             'silicone': 307,\n",
       "             'picky': 1,\n",
       "             'must': 1350,\n",
       "             '5': 5574,\n",
       "             'material': 4018,\n",
       "             'generation': 366,\n",
       "             'rings': 161,\n",
       "             'soap': 253,\n",
       "             'more': 5184,\n",
       "             'warm': 1133,\n",
       "             'i': 1515,\n",
       "             'clean': 2216,\n",
       "             'this': 13412,\n",
       "             'just': 2833,\n",
       "             'pancake': 22,\n",
       "             'children': 932,\n",
       "             'molder': 1,\n",
       "             'with': 21982,\n",
       "             'energetic': 48,\n",
       "             'gadget': 161,\n",
       "             'mouse': 277,\n",
       "             'washed': 247,\n",
       "             'is': 19446,\n",
       "             'than': 2803,\n",
       "             'oil': 472,\n",
       "             '2nd': 134,\n",
       "             'loving': 133,\n",
       "             'filled': 302,\n",
       "             'day': 2147,\n",
       "             'form': 729,\n",
       "             'order': 615,\n",
       "             'them': 2401,\n",
       "             'ring': 415,\n",
       "             'each': 1889,\n",
       "             'all': 8617,\n",
       "             'dishwasher': 348,\n",
       "             'mold': 104,\n",
       "             'enduring': 72,\n",
       "             'performance': 1749,\n",
       "             'foods': 139,\n",
       "             '4': 4939,\n",
       "             'pop': 177,\n",
       "             'funning': 3,\n",
       "             'camera': 1482,\n",
       "             'backpack': 203,\n",
       "             'nikon': 229,\n",
       "             'carry': 1293,\n",
       "             'lens': 794,\n",
       "             'canon': 289,\n",
       "             'smiledrive®': 3,\n",
       "             'pentax': 40,\n",
       "             'india': 2150,\n",
       "             'waterproof': 767,\n",
       "             'others': 447,\n",
       "             'dslr': 358,\n",
       "             'accessories': 1257,\n",
       "             'case': 1259,\n",
       "             'bag': 961,\n",
       "             'olympus': 70,\n",
       "             'desirica': 14,\n",
       "             'beautiful': 1780,\n",
       "             'tie': 309,\n",
       "             'important': 1085,\n",
       "             'tassels': 39,\n",
       "             'gold': 711,\n",
       "             'curtains': 218,\n",
       "             'backs': 58,\n",
       "             'curtain': 266,\n",
       "             'stylish': 2115,\n",
       "             'home': 5053,\n",
       "             'keep': 2674,\n",
       "             '12x1x1': 1,\n",
       "             'scented': 52,\n",
       "             'caution': 64,\n",
       "             'handling': 272,\n",
       "             'never': 1046,\n",
       "             'holder': 1028,\n",
       "             'christmas': 198,\n",
       "             'pets': 82,\n",
       "             'aromatic': 37,\n",
       "             'cool': 996,\n",
       "             'reach': 485,\n",
       "             'candle': 188,\n",
       "             'trim': 96,\n",
       "             'level': 1297,\n",
       "             'before': 1546,\n",
       "             'also': 6005,\n",
       "             'lwh': 3,\n",
       "             'candles': 140,\n",
       "             'inches': 1225,\n",
       "             'burn': 131,\n",
       "             'unattended': 20,\n",
       "             'burning': 168,\n",
       "             'extinguishes': 2,\n",
       "             'touching': 88,\n",
       "             'accessory': 628,\n",
       "             'sight': 76,\n",
       "             'allow': 650,\n",
       "             'leave': 386,\n",
       "             'tapered': 32,\n",
       "             'wick': 35,\n",
       "             'appropriate': 274,\n",
       "             'perfect': 4455,\n",
       "             'white': 3367,\n",
       "             'beauty': 613,\n",
       "             'gift': 1214,\n",
       "             'long': 3794,\n",
       "             'enhance': 638,\n",
       "             'occasion': 515,\n",
       "             'classic': 1083,\n",
       "             '12': 1835,\n",
       "             'fan': 553,\n",
       "             'flaunts': 16,\n",
       "             '1300': 41,\n",
       "             'completely': 632,\n",
       "             'powerful': 1482,\n",
       "             'sweep': 130,\n",
       "             'air': 1509,\n",
       "             'equipped': 610,\n",
       "             'rpm': 143,\n",
       "             'fresh': 765,\n",
       "             'orient': 39,\n",
       "             'grey': 895,\n",
       "             'electric': 700,\n",
       "             'size': 6655,\n",
       "             'matt': 92,\n",
       "             '225mm': 6,\n",
       "             'twelve': 63,\n",
       "             'has': 7664,\n",
       "             'blades': 396,\n",
       "             'bathroom': 749,\n",
       "             'inch': 2550,\n",
       "             'exhaust': 55,\n",
       "             'months': 469,\n",
       "             'warranty': 1430,\n",
       "             'colour': 3158,\n",
       "             'motor': 594,\n",
       "             '9': 1519,\n",
       "             'hill': 188,\n",
       "             'four': 769,\n",
       "             'delivery': 324,\n",
       "             'quality': 6489,\n",
       "             'competence': 10,\n",
       "             'expertise': 151,\n",
       "             'final': 179,\n",
       "             'prior': 107,\n",
       "             'piece': 1646,\n",
       "             'varied': 93,\n",
       "             'experience': 2634,\n",
       "             'prime': 192,\n",
       "             'testing': 195,\n",
       "             'stringent': 125,\n",
       "             'wastage': 45,\n",
       "             'couplers': 7,\n",
       "             'serving': 441,\n",
       "             'measures': 222,\n",
       "             'process': 665,\n",
       "             'high': 5812,\n",
       "             'throughout': 486,\n",
       "             'clients': 127,\n",
       "             'storage': 1972,\n",
       "             'kuber': 84,\n",
       "             'importance': 142,\n",
       "             'manufacturing': 487,\n",
       "             'our': 4002,\n",
       "             'that': 9904,\n",
       "             'type': 1831,\n",
       "             'pink': 633,\n",
       "             'technical': 498,\n",
       "             'large': 1487,\n",
       "             'featuring': 523,\n",
       "             'construction': 543,\n",
       "             'minimise': 16,\n",
       "             'pack': 2608,\n",
       "             'raw': 287,\n",
       "             'consistent': 135,\n",
       "             'woven': 213,\n",
       "             'ensured': 21,\n",
       "             'products': 2101,\n",
       "             'ii': 297,\n",
       "             'organiser': 73,\n",
       "             'x': 3882,\n",
       "             'successfully': 93,\n",
       "             'pride': 175,\n",
       "             'industries': 180,\n",
       "             'take': 1753,\n",
       "             'needs': 1432,\n",
       "             'suits': 247,\n",
       "             'collection': 1431,\n",
       "             'sleepsuit': 30,\n",
       "             'how': 1708,\n",
       "             'everyday': 734,\n",
       "             'subtle': 163,\n",
       "             'baby': 973,\n",
       "             'crafted': 957,\n",
       "             \"you're\": 411,\n",
       "             'pretty': 197,\n",
       "             'embroidery': 162,\n",
       "             'poppers': 18,\n",
       "             'fuss': 103,\n",
       "             'free': 3635,\n",
       "             'create': 952,\n",
       "             \"we've\": 90,\n",
       "             'mum': 6,\n",
       "             'carefully': 584,\n",
       "             'dreams': 203,\n",
       "             'print': 1132,\n",
       "             'dad': 93,\n",
       "             'sleep': 404,\n",
       "             'comfortable': 2496,\n",
       "             'including': 1567,\n",
       "             'looks': 879,\n",
       "             'mothercare': 59,\n",
       "             'sweet': 191,\n",
       "             'outfit': 215,\n",
       "             \"girls'\": 199,\n",
       "             'combined': 255,\n",
       "             'stretch': 347,\n",
       "             'floral': 349,\n",
       "             'thought': 418,\n",
       "             'even': 2523,\n",
       "             'love': 1291,\n",
       "             'one': 5798,\n",
       "             'changes': 205,\n",
       "             'wear': 2087,\n",
       "             'frills': 5,\n",
       "             'sure': 1108,\n",
       "             'rich': 910,\n",
       "             'designs': 890,\n",
       "             'fabrics': 376,\n",
       "             'faucets': 41,\n",
       "             'range': 2729,\n",
       "             'simpler': 70,\n",
       "             'finish': 1671,\n",
       "             'which': 5999,\n",
       "             'keeping': 1016,\n",
       "             'thereby': 110,\n",
       "             'finished': 549,\n",
       "             'mimics': 6,\n",
       "             'distribution': 143,\n",
       "             'curves': 104,\n",
       "             'yet': 881,\n",
       "             'compact': 1732,\n",
       "             'organic': 141,\n",
       "             'cock': 40,\n",
       "             'modern': 1503,\n",
       "             'lot': 507,\n",
       "             'notch': 85,\n",
       "             'elegant': 1377,\n",
       "             'bathrooms': 75,\n",
       "             'chrome': 424,\n",
       "             'aesthetics': 131,\n",
       "             'hindware': 39,\n",
       "             'faucet': 43,\n",
       "             'displayed': 100,\n",
       "             'gracefulness': 5,\n",
       "             'flora': 22,\n",
       "             'they': 2592,\n",
       "             'f280001cp': 2,\n",
       "             'whole': 800,\n",
       "             'gentle': 256,\n",
       "             'blooms': 9,\n",
       "             'higher': 432,\n",
       "             'inspired': 283,\n",
       "             'designed': 4016,\n",
       "             'pillar': 22,\n",
       "             'nature': 506,\n",
       "             'soft': 2714,\n",
       "             'now': 1801,\n",
       "             'lines': 255,\n",
       "             'fluid': 107,\n",
       "             'stereo': 633,\n",
       "             '8': 2753,\n",
       "             '5mm': 574,\n",
       "             'cable': 1556,\n",
       "             'feet': 1165,\n",
       "             'amazonbasics': 381,\n",
       "             'audio': 1548,\n",
       "             'male': 312,\n",
       "             'hacker': 9,\n",
       "             'half': 485,\n",
       "             'games': 363,\n",
       "             'talents': 20,\n",
       "             'author': 4464,\n",
       "             'hacking': 14,\n",
       "             'kevin': 23,\n",
       "             '1981': 88,\n",
       "             'computer': 1056,\n",
       "             'either': 303,\n",
       "             'plea': 2,\n",
       "             'security': 540,\n",
       "             'reformed': 2,\n",
       "             'war': 258,\n",
       "             'voiding': 9,\n",
       "             '17': 493,\n",
       "             'hardware': 346,\n",
       "             'about': 6180,\n",
       "             'says': 118,\n",
       "             'mitnick': 1,\n",
       "             'been': 2855,\n",
       "             'bargain': 22,\n",
       "             'life': 3092,\n",
       "             'hack': 9,\n",
       "             'nearly': 241,\n",
       "             'editor': 297,\n",
       "             'alleged': 2,\n",
       "             'age': 781,\n",
       "             'since': 1131,\n",
       "             'he': 2870,\n",
       "             'world': 2386,\n",
       "             'books': 2461,\n",
       "             'adult': 165,\n",
       "             'at': 7743,\n",
       "             'norad': 1,\n",
       "             '2000': 401,\n",
       "             'arrest': 9,\n",
       "             'prison': 22,\n",
       "             'devoting': 3,\n",
       "             'movie': 198,\n",
       "             'most': 3908,\n",
       "             'fugitive': 1,\n",
       "             'release': 375,\n",
       "             'helping': 277,\n",
       "             'famous': 310,\n",
       "             '1982': 55,\n",
       "             'spent': 177,\n",
       "             'subject': 472,\n",
       "             'while': 2714,\n",
       "             'look': 3406,\n",
       "             'wood': 1029,\n",
       "             'servers': 33,\n",
       "             'bowls': 109,\n",
       "             'go': 1645,\n",
       "             'ht10': 1,\n",
       "             'eco': 353,\n",
       "             'salad': 107,\n",
       "             'exclusive': 461,\n",
       "             'colorful': 242,\n",
       "             'some': 1219,\n",
       "             'diameter': 602,\n",
       "             'decorative': 608,\n",
       "             'again': 439,\n",
       "             'wipe': 154,\n",
       "             'hands': 730,\n",
       "             'height': 927,\n",
       "             '20': 1303,\n",
       "             'friendly': 1175,\n",
       "             'wooden': 759,\n",
       "             'gorgeous': 209,\n",
       "             'bowl': 310,\n",
       "             'mango': 59,\n",
       "             'handmade': 345,\n",
       "             'reuse': 21,\n",
       "             'spoon': 190,\n",
       "             'cloth': 799,\n",
       "             'dia': 99,\n",
       "             '30': 1384,\n",
       "             'cm': 1779,\n",
       "             'on': 11741,\n",
       "             'pasta': 83,\n",
       "             'angle': 629,\n",
       "             'seconds': 412,\n",
       "             'serrated': 48,\n",
       "             'hones': 17,\n",
       "             'sharpener': 57,\n",
       "             'edge': 549,\n",
       "             'motorised': 20,\n",
       "             'hold': 956,\n",
       "             'features': 4123,\n",
       "             'cordless': 68,\n",
       "             'sleek': 637,\n",
       "             'scissors': 84,\n",
       "             'knife': 298,\n",
       "             'two': 2201,\n",
       "             'wheel': 138,\n",
       "             'countertop': 30,\n",
       "             'stage': 319,\n",
       "             'blade': 411,\n",
       "             'restores': 13,\n",
       "             'larger': 229,\n",
       "             'shavings': 9,\n",
       "             'tray': 366,\n",
       "             'paring': 43,\n",
       "             'siddhi': 14,\n",
       "             'sharpening': 66,\n",
       "             'knives': 133,\n",
       "             'system': 1940,\n",
       "             'catch': 144,\n",
       "             'slide': 265,\n",
       "             'sharp': 536,\n",
       "             'whether': 756,\n",
       "             'swifty': 7,\n",
       "             'precision': 383,\n",
       "             'fillet': 6,\n",
       "             'collect': 61,\n",
       "             'too': 840,\n",
       "             'automatically': 518,\n",
       "             'unit': 681,\n",
       "             'mineral': 48,\n",
       "             'stone': 201,\n",
       "             'insert': 299,\n",
       "             'clippers': 8,\n",
       "             'power': 3562,\n",
       "             'hedge': 17,\n",
       "             'perfection': 178,\n",
       "             'household': 472,\n",
       "             'steak': 55,\n",
       "             'product': 5869,\n",
       "             'razor': 61,\n",
       "             'cleavers': 8,\n",
       "             'speed': 1411,\n",
       "             'press': 746,\n",
       "             'small': 2022,\n",
       "             'button': 1014,\n",
       "             'chef': 116,\n",
       "             'built': 1787,\n",
       "             'fast': 1036,\n",
       "             'guide': 1096,\n",
       "             'professional': 1195,\n",
       "             'rotating': 171,\n",
       "             'smooth': 1257,\n",
       "             'works': 1535,\n",
       "             'connector': 401,\n",
       "             '6m': 36,\n",
       "             'black': 5960,\n",
       "             'slim': 853,\n",
       "             'condeser': 1,\n",
       "             'usb': 2014,\n",
       "             'microphone': 397,\n",
       "             'sl': 33,\n",
       "             'quantum': 92,\n",
       "             '0': 2439,\n",
       "             'length': 1942,\n",
       "             'hub': 149,\n",
       "             'port': 884,\n",
       "             'plugx12': 1,\n",
       "             'cord': 560,\n",
       "             'printed': 893,\n",
       "             'tables': 199,\n",
       "             '–': 777,\n",
       "             'covering': 216,\n",
       "             'add': 1318,\n",
       "             'really': 442,\n",
       "             'attractive': 1124,\n",
       "             'living': 1201,\n",
       "             '❏homize': 2,\n",
       "             'dressers': 10,\n",
       "             'office': 1730,\n",
       "             'pattern': 892,\n",
       "             'bottom': 837,\n",
       "             'room': 2102,\n",
       "             'homize': 9,\n",
       "             'simply': 1068,\n",
       "             'box': 1315,\n",
       "             'tissue': 122,\n",
       "             'design': 5486,\n",
       "             '❏when': 2,\n",
       "             'note': 1334,\n",
       "             'directly': 529,\n",
       "             'lace': 228,\n",
       "             'name': 3205,\n",
       "             'not': 5529,\n",
       "             'trimmings': 17,\n",
       "             'cardboard': 27,\n",
       "             'car': 1116,\n",
       "             'buy': 1025,\n",
       "             'included': 1402,\n",
       "             '\\xa0': 1450,\n",
       "             'color': 5371,\n",
       "             'often': 479,\n",
       "             'tissues': 26,\n",
       "             'remove': 668,\n",
       "             'paper': 842,\n",
       "             'ornamental': 12,\n",
       "             'hard': 1110,\n",
       "             'dining': 556,\n",
       "             'cover': 1655,\n",
       "             '❏': 2,\n",
       "             'napkin': 115,\n",
       "             'there': 1603,\n",
       "             'velvet': 112,\n",
       "             'market': 557,\n",
       "             'close': 431,\n",
       "             'napkins': 77,\n",
       "             'fill': 239,\n",
       "             'comprises': 212,\n",
       "             'wearing': 616,\n",
       "             'bathrobe': 63,\n",
       "             'bath': 314,\n",
       "             'sleeve': 628,\n",
       "             'elevanto': 10,\n",
       "             'royalblue': 1,\n",
       "             'regular': 1179,\n",
       "             'gown': 132,\n",
       "             'from\\xa0elevanto\\xa0made': 3,\n",
       "             'pocket': 804,\n",
       "             'feel': 1555,\n",
       "             '4th': 91,\n",
       "             'robe': 98,\n",
       "             'premium': 1698,\n",
       "             'blue': 2120,\n",
       "             'strips': 81,\n",
       "             'matching': 254,\n",
       "             'fit': 2744,\n",
       "             'terry': 187,\n",
       "             'normal': 520,\n",
       "             'sls': 9,\n",
       "             'g': 719,\n",
       "             'paraben': 28,\n",
       "             'coffee': 589,\n",
       "             'removal': 201,\n",
       "             'body': 1930,\n",
       "             'naked': 27,\n",
       "             'tan': 39,\n",
       "             'mcaffeine': 3,\n",
       "             'scrub': 90,\n",
       "             'oily': 23,\n",
       "             'coconut': 43,\n",
       "             'skin': 979,\n",
       "             'kids': 1528,\n",
       "             'mlodinow': 9,\n",
       "             'hawking': 59,\n",
       "             'position': 569,\n",
       "             'cambridge': 180,\n",
       "             'collaborator': 11,\n",
       "             'nutshell': 30,\n",
       "             'window': 388,\n",
       "             'trek': 19,\n",
       "             'edition': 869,\n",
       "             'reader': 526,\n",
       "             'years': 2693,\n",
       "             'other': 4562,\n",
       "             'leonard': 23,\n",
       "             \"children's\": 151,\n",
       "             'physicist': 35,\n",
       "             'stephen': 143,\n",
       "             'professor': 847,\n",
       "             'tech': 235,\n",
       "             'history': 784,\n",
       "             \"feynman's\": 16,\n",
       "             'essay': 94,\n",
       "             'book': 3640,\n",
       "             'universe': 134,\n",
       "             'mathematics': 232,\n",
       "             'elementary': 45,\n",
       "             'holes': 239,\n",
       "             'next': 690,\n",
       "             'rainbow': 54,\n",
       "             'cal': 14,\n",
       "             'universes': 7,\n",
       "             'include': 900,\n",
       "             'taught': 292,\n",
       "             'series': 1043,\n",
       "             'briefer': 27,\n",
       "             'lucasian': 31,\n",
       "             'thirty': 168,\n",
       "             'general': 649,\n",
       "             'held': 232,\n",
       "             'university': 1236,\n",
       "             \"euclid's\": 6,\n",
       "             'time': 4448,\n",
       "             'einstein': 43,\n",
       "             'written': 963,\n",
       "             'co': 446,\n",
       "             'simple': 1674,\n",
       "             'chair': 576,\n",
       "             'delightful': 103,\n",
       "             'wicker': 35,\n",
       "             'balcony': 241,\n",
       "             'seating': 137,\n",
       "             'provides': 2321,\n",
       "             'virasat': 1,\n",
       "             'rattan': 33,\n",
       "             'furnishing': 111,\n",
       "             'seater': 234,\n",
       "             'garden': 520,\n",
       "             'brown': 1089,\n",
       "             'furniture': 704,\n",
       "             'glass': 1360,\n",
       "             'stand': 1309,\n",
       "             'chairs': 250,\n",
       "             '43x24x38cm': 1,\n",
       "             'option': 518,\n",
       "             'up': 5793,\n",
       "             'necktie': 39,\n",
       "             'lapel': 77,\n",
       "             'square': 435,\n",
       "             'mensome': 6,\n",
       "             'cufflinks': 28,\n",
       "             \"men's\": 1437,\n",
       "             'pin': 421,\n",
       "             'achieve': 320,\n",
       "             'methods': 529,\n",
       "             'commentary': 55,\n",
       "             'reading': 777,\n",
       "             '2017this': 9,\n",
       "             'my': 779,\n",
       "             'key': 978,\n",
       "             'numerous': 359,\n",
       "             'over': 2562,\n",
       "             'described': 123,\n",
       "             'ever': 844,\n",
       "             'successful': 320,\n",
       "             'wants': 201,\n",
       "             'necessary': 260,\n",
       "             'adding': 254,\n",
       "             \"family's\": 36,\n",
       "             'customeron': 24,\n",
       "             'review': 2258,\n",
       "             'examples': 160,\n",
       "             'gives': 1798,\n",
       "             'july': 74,\n",
       "             'develop': 264,\n",
       "             'mar': 19,\n",
       "             'napoleon': 93,\n",
       "             'among': 427,\n",
       "             'every': 2445,\n",
       "             'copies': 213,\n",
       "             'energy': 751,\n",
       "             'stories': 528,\n",
       "             'going': 457,\n",
       "             'its': 4642,\n",
       "             'sold': 388,\n",
       "             'intense': 95,\n",
       "             'goals': 83,\n",
       "             'extremely': 753,\n",
       "             'something': 422,\n",
       "             'definitely': 254,\n",
       "             'development': 511,\n",
       "             'sole': 96,\n",
       "             'self': 1005,\n",
       "             'read': 1348,\n",
       "             'million': 385,\n",
       "             '2012': 235,\n",
       "             'passion': 259,\n",
       "             'change': 811,\n",
       "             'literature': 397,\n",
       "             'containing': 114,\n",
       "             'authored': 224,\n",
       "             'sapan': 6,\n",
       "             'chapter': 269,\n",
       "             'always': 983,\n",
       "             'promoted': 25,\n",
       "             'today': 805,\n",
       "             'american': 690,\n",
       "             'known': 800,\n",
       "             'being': 1065,\n",
       "             'information': 651,\n",
       "             'loved': 470,\n",
       "             'quick': 1107,\n",
       "             \"'personal\": 6,\n",
       "             'grow': 295,\n",
       "             'chapters': 182,\n",
       "             'ones': 547,\n",
       "             'atom': 44,\n",
       "             'think': 611,\n",
       "             'abided': 6,\n",
       "             'had': 559,\n",
       "             \"i've\": 103,\n",
       "             'contains': 673,\n",
       "             'firmly': 286,\n",
       "             'an': 8710,\n",
       "             'get': 2642,\n",
       "             'thinking': 274,\n",
       "             'anybody': 47,\n",
       "             'believe': 295,\n",
       "             'back': 2022,\n",
       "             'byamazon': 31,\n",
       "             'am': 217,\n",
       "             'journalist': 155,\n",
       "             'lecturer': 141,\n",
       "             '1930s': 11,\n",
       "             'mindset': 13,\n",
       "             'follows': 103,\n",
       "             'maniyar': 6,\n",
       "             'divided': 53,\n",
       "             'june': 108,\n",
       "             '2017the': 11,\n",
       "             'principle': 62,\n",
       "             'well': 3065,\n",
       "             \"friend's\": 24,\n",
       "             'producers': 50,\n",
       "             'earliest': 50,\n",
       "             '19': 541,\n",
       "             'success': 446,\n",
       "             'inspirational': 105,\n",
       "             'was': 2101,\n",
       "             'period': 279,\n",
       "             '1895': 16,\n",
       "             'omission': 2,\n",
       "             'called': 270,\n",
       "             'conclud\\xading': 1,\n",
       "             'grappling': 5,\n",
       "             'earlier': 74,\n",
       "             'volume': 649,\n",
       "             'voluminous': 8,\n",
       "             'view': 640,\n",
       "             'considerably': 16,\n",
       "             'undertook': 11,\n",
       "             'confusion': 22,\n",
       "             'difficulties': 27,\n",
       "             'may': 1867,\n",
       "             'avoid': 609,\n",
       "             'what': 1703,\n",
       "             'here': 699,\n",
       "             '1660': 4,\n",
       "             '1780': 2,\n",
       "             'scheme': 33,\n",
       "             'obtained': 49,\n",
       "             'bibliographical': 1,\n",
       "             'dislocation': 3,\n",
       "             'execution': 23,\n",
       "             'between': 1327,\n",
       "             'index': 67,\n",
       "             'reserve': 26,\n",
       "             'comprehensive': 370,\n",
       "             'task': 188,\n",
       "             'but': 2698,\n",
       "             'few': 630,\n",
       "             'circumstances': 38,\n",
       "             'present': 403,\n",
       "             'greatly': 82,\n",
       "             'occurred': 32,\n",
       "             'slight': 226,\n",
       "             'criticism': 51,\n",
       "             'century': 283,\n",
       "             'would': 1052,\n",
       "             'bookshops': 1,\n",
       "             'did': 243,\n",
       "             'provide': 1572,\n",
       "             'better': 1557,\n",
       "             'writers': 251,\n",
       "             'immediate': 60,\n",
       "             'seemed': 42,\n",
       "             'volumes': 96,\n",
       "             'second': 455,\n",
       "             'greater': 284,\n",
       "             'repetition': 6,\n",
       "             'kept': 223,\n",
       "             'nineteenth': 14,\n",
       "             'part': 1005,\n",
       "             'trouble': 104,\n",
       "             'predecessor': 14,\n",
       "             'con\\xadnecting': 1,\n",
       "             'exceptions': 12,\n",
       "             'less': 965,\n",
       "             'themselves': 183,\n",
       "             'merely': 40,\n",
       "             'corresponding': 41,\n",
       "             'elizabethan': 3,\n",
       "             'inner': 438,\n",
       "             'multi': 1788,\n",
       "             'pockets': 300,\n",
       "             'saves': 256,\n",
       "             'travel': 770,\n",
       "             'detachable': 275,\n",
       "             'aunts': 1,\n",
       "             'cosmetics': 62,\n",
       "             'getko': 13,\n",
       "             'mommy': 20,\n",
       "             'ease': 883,\n",
       "             'socks': 342,\n",
       "             'pouch': 271,\n",
       "             'innerwear': 114,\n",
       "             'space': 1810,\n",
       "             'shirts': 299,\n",
       "             'undergarments': 47,\n",
       "             'cosmetic': 42,\n",
       "             'middle': 237,\n",
       "             'undershirts': 2,\n",
       "             'girls': 1053,\n",
       "             'ladies': 186,\n",
       "             'opening': 410,\n",
       "             'under': 1253,\n",
       "             'victoria': 15,\n",
       "             'taking': 405,\n",
       "             'zip': 204,\n",
       "             'fits': 769,\n",
       "             'compartment': 146,\n",
       "             'secret': 200,\n",
       "             'organizing': 98,\n",
       "             'kit': 894,\n",
       "             'underwear': 88,\n",
       "             'together': 762,\n",
       "             'clothing': 476,\n",
       "             'lightweight': 1343,\n",
       "             'inside': 1230,\n",
       "             'nylon': 391,\n",
       "             'toiletries': 25,\n",
       "             'luggage': 50,\n",
       "             'top': 2535,\n",
       "             'toiletry': 11,\n",
       "             'bras': 61,\n",
       "             'resistant': 1040,\n",
       "             ...})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The last dimension of the inputs to a Dense layer should be defined. Found None. Full input shape received: (None, None)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# define network\u001b[39;00m\n\u001b[1;32m      2\u001b[0m n_words \u001b[38;5;241m=\u001b[39m x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m define_model(n_words)\n",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m, in \u001b[0;36mdefine_model\u001b[0;34m(vocab_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling1D(pool_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Flatten())\n\u001b[0;32m----> 9\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m10\u001b[39m, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m,  activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# compile network\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.11/site-packages/tensorflow/python/trackable/base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.11/site-packages/keras/src/layers/core/dense.py:148\u001b[0m, in \u001b[0;36mDense.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    146\u001b[0m last_dim \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mdimension_value(input_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m last_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe last dimension of the inputs to a Dense layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould be defined. Found None. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull input shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    152\u001b[0m     )\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m InputSpec(min_ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m: last_dim})\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    156\u001b[0m     shape\u001b[38;5;241m=\u001b[39m[last_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m     trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    162\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: The last dimension of the inputs to a Dense layer should be defined. Found None. Full input shape received: (None, None)"
     ]
    }
   ],
   "source": [
    "# define network\n",
    "n_words = x_train.shape[1]\n",
    "model = define_model(n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44277"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words = x_train.shape[1]\n",
    "n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 21:25:25.574001: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 320565480 exceeds 10% of free system memory.\n",
      "2023-12-17 21:25:25.912083: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 320565480 exceeds 10% of free system memory.\n",
      "2023-12-17 21:25:26.627587: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2023-12-17 21:25:26.765731: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-17 21:25:26.968766: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-12-17 21:25:27.094019: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-12-17 21:25:27.371071: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-12-17 21:25:27.496157: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-12-17 21:25:27.681672: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-17 21:25:28.027986: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fa8c820b950 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-17 21:25:28.028010: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2023-12-17 21:25:28.038082: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1702828528.112242   24559 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 15s 67ms/step - loss: 0.6934 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 12s 67ms/step - loss: 0.6932 - accuracy: 0.4928\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 12s 67ms/step - loss: 0.6933 - accuracy: 0.4906\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 12s 67ms/step - loss: 0.6932 - accuracy: 0.5028\n",
      "Epoch 5/10\n",
      "181/181 [==============================] - 12s 67ms/step - loss: 0.6932 - accuracy: 0.5028\n",
      "Epoch 6/10\n",
      "181/181 [==============================] - 12s 67ms/step - loss: 0.6932 - accuracy: 0.4917\n",
      "Epoch 7/10\n",
      "181/181 [==============================] - 12s 67ms/step - loss: 0.6932 - accuracy: 0.5028\n",
      "Epoch 8/10\n",
      "181/181 [==============================] - 12s 68ms/step - loss: 0.6932 - accuracy: 0.5028\n",
      "Epoch 9/10\n",
      "181/181 [==============================] - 12s 68ms/step - loss: 0.6932 - accuracy: 0.5028\n",
      "Epoch 10/10\n",
      "181/181 [==============================] - 12s 68ms/step - loss: 0.6932 - accuracy: 0.5028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fac1f8351d0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, np.array(train_labels), epochs = 10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, show_dtype=True, show_layer_activations = True, show_shapes = True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 21:27:31.362835: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 35421600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6931546926498413, 0.5]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,np.array(test_labels), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'Best movie ever! It was great, I will definitely recommend it.'\n",
    "text2 = 'This is a bad movie.'\n",
    "text3 = 'This is a best movie'\n",
    "text4 = 'The acting was bad in this movie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "  tokens = clean_doc(text)\n",
    "  text = \" \".join(tokens)\n",
    "  x_test = tokenizer.texts_to_matrix([text], mode = 'binary')\n",
    "  prediction = model.predict(x_test)\n",
    "  if prediction >= 0.5:\n",
    "    return 'Positive'\n",
    "  else:\n",
    "     return 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify a review a negative or positive\n",
    "def predict_sentiment(review):\n",
    "  #clean\n",
    "  tokens = clean_doc(review)\n",
    "  # Convert to line\n",
    "  line = ' '.join(tokens)\n",
    "  # encode\n",
    "  encoded = tokenizer.texts_to_matrix([line], mode = 'binary')\n",
    "  # predict sentiment\n",
    "  yhat = model.predict(encoded, verbose=0)\n",
    "  # retrieve predicted percentage and lable\n",
    "  percent_pos = yhat[0 ,0]\n",
    "  if round(percent_pos) == 0:\n",
    "    return (1-percent_pos), 'NEGATIVE'\n",
    "  return percent_pos, \"POSITIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: [Best movie ever! It was great, I will definitely recommend it.]\n",
      " Sentiment: NEGATIVE (0.502%)\n"
     ]
    }
   ],
   "source": [
    "percent, sentiment = predict_sentiment(text1)\n",
    "print('Review: [%s]\\n Sentiment: %s (%.3f%%)' % (text1, sentiment, percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: [Best movie ever! It was great, I will definitely recommend it.]\n",
      " Sentiment: NEGATIVE (0.502%)\n"
     ]
    }
   ],
   "source": [
    "percent, sentiment = predict_sentiment(text2)\n",
    "print(f'Review: [{text1}]\\n Sentiment: {sentiment} ({percent:.3f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5017190873622894, 'NEGATIVE')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5017190873622894, 'NEGATIVE')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(text4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
